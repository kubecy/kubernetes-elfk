# ES集群部署(二进制)

## 1.下载 elasticsearch 7.10.2 版本

>:mag:https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.10.2-linux-x86_64.tar.gz

## 2.elasticsearch 集群架构

1. 日志类业务，通常情况下首选热温架构。如果有数据归档存储需求，可加入冷节点存储归档数据。
2. 热节点使用高速SSD+小内存机器，温节点使用低速HDD+大内存机器，冷节点使用最便宜的DAS/SAN/磁带存储，组合达到最大性能和最低成本。
3. 原始数据量和索引后所占磁盘空间之间的比例大约为 1.1，所以20GB的原始数据预计会在磁盘上产生 22GB的索引数据。加上副本分片（通常为1副本）后，此数值会翻倍，每天为44GB。
4. 在30天内，主副分片占用量为1320GB，加上归档存储30天的数据（通常为0副本）占用量660GB，总计1980GB

## 3.环境检查（在所有节点执行）

### 3.1.目录权限检查

>1. 所有新建服务器操作系统为RHEL8.8。
>2. 所有新建服务器已单独挂载程序目录 /app  /appdata  /applog
>3. 所有新建服务器的 ES 启动用户名，UID，GID 完全一致。

| 文件系统 | 格式化类型 | 容量 | 所属用户              | 所属用户组            | 权限 |
| -------- | ---------- | ---- | --------------------- | --------------------- | ---- |
| /app     | XFS        | 30G  | elasticsearch（2563） | elasticsearch（2563） | 755  |
| /appdata | XFS        | 6T   | elasticsearch（2563） | elasticsearch（2563） | 755  |
| /applog  | XFS        | 50G  | elasticsearch（2563） | elasticsearch（2563） | 755  |

### 3.1.1.目录权限配置

~~~shell
##1.创建目录
root@MES01 /root # mkdir -p /app /appdata/MMBAN-ES/ /applog/eslog/MMBAN-ES

##2.创建所属用户组和所属用户
root@MES01 /root # groupadd  -g 2563 elasticsearch && useradd  -u 2563  -g 2563 elasticsearch

##3.创建文件系统
###3.1创建VG
root@MES01 /root # vgcreate  datavg  /dev/sdb{1..3}
  Physical volume "/dev/sdb1" successfully created.
  Physical volume "/dev/sdb2" successfully created.
  Physical volume "/dev/sdb3" successfully created.
  Volume group "datavg" successfully created
............省略

###3.2创建LV
root@MES01 /root # lvcreate -L 5G -n lv_app datavg
root@MES01 /root # lvcreate -L 5G -n lv_appdata datavg
root@MES01 /root # lvcreate -L 5G -n lv_applog datavg
............省略

###3.3格式化
root@MES01 /root # mkfs.xfs   /dev/datavg/lv_app 
root@MES01 /root # mkfs.xfs   /dev/datavg/lv_appdata 
root@MES01 /root # mkfs.xfs   /dev/datavg/lv_applog 
............省略

###3.4挂载
............省略

###3.4目录授权
root@MES01 /root # chown  -R elasticsearch:elasticsearch /appdata /applog /app

root@MES01 /root # cat >> /etc/hosts  << EOF
192.168.1.51 MES01
192.168.1.52 MES02
192.168.1.53 MES03
192.168.1.61 DES01
192.168.1.62 DES02
192.168.1.63 DES03
192.168.1.64 DES04
192.168.1.65 DES05
192.168.1.66 DES06
EOF
~~~

### 3.2.基础环境配置

#### 3.2.1.系统内核版本检查

~~~shell
root@MES01 /root # cat /etc/redhat-release 
Red Hat Enterprise Linux release 8.8 (Ootpa)

root@MES01 /root # uname -r                
4.18.0-477.10.1.el8_8.x86_64
~~~

#### 3.2.2.停用系统 swap

~~~shell
root@MES01 /root # swapoff -a

root@MES01 /root # sed -i '/swap/s/^/#/' /etc/fstab  

root@LMES01 /root # grep  -iw swap /etc/fstab 
##/dev/mapper/rhel-swap   none                    swap    defaults        0 0
~~~

#### 3.2.3.系统优化

>内核参数配置

~~~~shell
##1.内存参数配置优化
root@MES01 /root # cat > /etc/sysctl.d/elasticsearch.conf << EOF
net.core.rmem_default = 256960
net.core.rmem_max = 513920
net.core.wmem_default = 256960
net.core.wmem_max = 513920
net.core.netdev_max_backlog = 2000
net.core.somaxconn = 2048
net.core.optmem_max = 81920

net.ipv4.tcp_mem = 131072 262144 524288
net.ipv4.tcp_rmem = 8760 256960 4088000
net.ipv4.tcp_wmem = 8760 256960 4088000

net.ipv4.tcp_keepalive_time = 1800
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 3

net.ipv4.tcp_sack = 1
net.ipv4.tcp_fack = 1
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_syncookies = 1

net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 30

net.ipv4.ip_local_port_range = 1024 65000
net.ipv4.tcp_max_syn_backlog = 2048
vm.max_map_count = 524288
EOF


################################
##2.加载文件
root@MES01 /root # sysctl -f /etc/sysctl.d/elasticsearch.conf 
net.core.rmem_default = 256960
net.core.rmem_max = 513920
net.core.wmem_default = 256960
net.core.wmem_max = 513920
net.core.netdev_max_backlog = 2000
net.core.somaxconn = 2048
net.core.optmem_max = 81920
net.ipv4.tcp_mem = 131072 262144 524288
net.ipv4.tcp_rmem = 8760 256960 4088000
net.ipv4.tcp_wmem = 8760 256960 4088000
net.ipv4.tcp_keepalive_time = 1800
net.ipv4.tcp_keepalive_intvl = 30
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.tcp_sack = 1
net.ipv4.tcp_fack = 1
net.ipv4.tcp_timestamps = 1
net.ipv4.tcp_window_scaling = 1
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_tw_reuse = 1
net.ipv4.tcp_fin_timeout = 30
net.ipv4.ip_local_port_range = 1024 65000
net.ipv4.tcp_max_syn_backlog = 2048
vm.max_map_count = 524288

##3.验证
root@MES01 /root # sysctl -a | grep -i vm.max_map_count
vm.max_map_count = 524288
~~~~

>系统文件描述符优化

~~~shell
##1.系统文件描述符优化配置
root@MES01 /root # cat > /etc/security/limits.conf    << EOF
####################################### /etc/security/limits.conf
*     hard  memlock     unlimited
*     soft  memlock     unlimited
*     soft  msgqueue    8192000
*     hard  msgqueue    8192000
*     soft  nofile      1048576
*     hard  nofile      1048576
*     soft  nproc       1000000
*     hard  nproc       1000000
*     soft  core        unlimited
*     hard  core        unlimited
##root
root     hard  memlock     32000
root     soft  memlock     32000
root     soft  msgqueue    8192000
root     hard  msgqueue    8192000
root     soft  nofile      1048576
root     hard  nofile      1048576
root     soft  nproc       1000000
root     hard  nproc       1000000
root     soft  core        unlimited
root     hard  core        unlimited
EOF


##2.重新登录会话生效 (exit)


##3.使用 ulimit 命令验证配置是否生效。
ulimit -l  # 验证 memlock
ulimit -q  # 验证 msgqueue
ulimit -n  # 验证 nofile
ulimit -u  # 验证 nproc
ulimit -c  # 验证 core
~~~

## 4.安装 elasticsearch 7.17.5(使用elasticsearch用户操作)

### 4.1. 解压 elasticsearch（在MES01 执行）

```shell
##1.解压到/app目录
root@MES01 /opt # tar  xvf  /opt/elasticsearch-7.17.5-linux-x86_64.tar.gz  -C /app
```

### 4.2.配置OpenJDK

~~~shell
root@MES01 /app/elasticsearch-7.17.5/jdk # cat > /etc/profile.d/elasticsearch.sh << "EOF"
##elasticsearch
export JAVA_HOME=/app/elasticsearch-7.17.5/jdk/
export PATH=$PATH:$JAVA_HOME/bin
EOF

##1.记载文件
root@MES01 /app/elasticsearch-7.17.5/jdk # source /etc/profile.d/elasticsearch.sh 

##2.验证
root@MES01 /app/elasticsearch-7.17.5/jdk # java -version                                 
openjdk version "18.0.1.1" 2022-04-22
OpenJDK Runtime Environment (build 18.0.1.1+2-6)
OpenJDK 64-Bit Server VM (build 18.0.1.1+2-6, mixed mode, sharing)
~~~

### 4.3.配置文件

#### 4.3.1.elasticsearch 文件

>MASTER节点

>- cluster.name 定义集群名
>- node.name 定义节点名
>- network.host 定义绑定 IP 地址，*site* 代表自动获取本地的内网 IP，如172.x.x.x
>- discovery.seed_hosts 用于节点发现，IP/hostname 均可
>- cluster.initial_master_node 用于初始化第一次时选举 master 节点，填写 node name
>- path.data 定义数据目录 path.logs 定义日志目录
>- http.port 定义 http服务的端口
>- transport.port 定义 tcp 服务的端口

~~~shell
root@MES01 /app # cp -p /app/elasticsearch-7.17.5/config/elasticsearch.yml /app/elasticsearch-7.17.5/config/elasticsearch.yml.bak


##1.master节点
root@MES01 /app/elasticsearch-7.17.5/config # cat > /app/elasticsearch-7.17.5/config/elasticsearch.yml << "EOF"
##集群名称
cluster.name: MMBAN-ES
##节点名称
node.name: ${HOSTNAME}
#数据目录
path.data: /appdata/MMBAN-ES
##日志目录
path.logs: /applog/eslog/MMBAN-ES
#
network.host: ${HOSTNAME}
#
#http.port: 9205
#transport.tcp.port: 9305
##路由节点，用于集群发现，一般配置所有候选Master节点
discovery.seed_hosts: ["MES01", "MES02","MES03"]
##初始化节点，用户首次加入集群，一般配置为主Master节点
cluster.initial_master_nodes: ["MES01"]

indices.fielddata.cache.size: 40%
bootstrap.memory_lock: true

##节点角色定义
#通用部署：Master管理节点，data数据节点，ingest预处理节点
#多层部署：Master管理节点，data_content通用数据节点，data_hot热数据节点，data_warm温数据节点，ingest预处理节点
#node.roles: [data,master,inges]

##MES01-MES03配置如下
node.master: true
node.data: false

##DES01-LDES06配置如下
#node.master: false
#node.data: true

##节点最大分片数，默认1000，按需配置
cluster.max_shards_per_node: 10000

##优化类配置，集群开始恢复的节点数、等待时间条件
#gateway.recover_after_nodes: 3

#gateway.expected_nodes: 5

#gateway.recover_after_time: 10m
EOF
~~~

>DATA节点

~~~shell
root@DES01 /app/elasticsearch-7.17.5/config # cat > /app/elasticsearch-7.17.5/config/elasticsearch.yml << "EOF"
##集群名称
cluster.name: MMBAN-ES
##节点名称
node.name: ${HOSTNAME}
#数据目录
path.data: /appdata/MMBAN-ES
##日志目录
path.logs: /applog/eslog/MMBAN-ES
#
network.host: ${HOSTNAME}
#
#http.port: 9205
#transport.tcp.port: 9305
##路由节点，用于集群发现，一般配置所有候选Master节点
discovery.seed_hosts: ["MES01", "MES02","MES03"]
##初始化节点，用户首次加入集群，一般配置为主Master节点
cluster.initial_master_nodes: ["MES01"]

indices.fielddata.cache.size: 40%
bootstrap.memory_lock: true

##节点角色定义
#通用部署：Master管理节点，data数据节点，ingest预处理节点
#多层部署：Master管理节点，data_content通用数据节点，data_hot热数据节点，data_warm温数据节点，ingest预处理节点

#node.roles: [data,master,inges]

##MES01-MES03配置如下
#node.master: true
#node.data: false

##DES01-DES06配置如下
node.master: false
node.data: true

##节点最大分片数，默认1000，按需配置
cluster.max_shards_per_node: 10000


##优化类配置，集群开始恢复的节点数、等待时间条件
#gateway.recover_after_nodes: 3

#gateway.expected_nodes: 5

#gateway.recover_after_time: 10m
EOF
~~~

#### 4.3.2.JVM 文件

>默认情况下，Elasticsearch 会根据节点的角色和总内存自动设置 JVM 堆大小。对于大多数生产环境，建议使用默认大小调整。
>
>实际生产环境中计算公式：**min（机器内存的一半，32GB内存）**。也就是说：取机器环境内存的一半和32GB内存之间的小值。
>
>要覆盖缺省堆大小，设置最小和最大堆大小设置，以及 。最小值和最大值必须相同。Xms Xmx

~~~shell
root@MES01 /app/elasticsearch-7.17.5/config # cp -p /app/elasticsearch-7.17.5/config/jvm.options  /app/elasticsearch-7.17.5/config/jvm.options.bak
root@MES01 /app/elasticsearch-7.17.5/config # cat > /app/elasticsearch-7.17.5/config/jvm.options << "EOF"
-Xms512M ##按需配置，一般为主机内存的一般，最大32G。
-Xmx512M
8-13:-XX:+UseConcMarkSweepGC
8-13:-XX:CMSInitiatingOccupancyFraction=75
8-13:-XX:+UseCMSInitiatingOccupancyOnly
14-:-XX:+UseG1GC
14-:-XX:G1ReservePercent=25
14-:-XX:InitiatingHeapOccupancyPercent=30
-Djava.io.tmpdir=${ES_TMPDIR}
-XX:+HeapDumpOnOutOfMemoryError
#9-:-XX:+ExitOnOutOfMemoryError
-XX:HeapDumpPath=/applog/eslog/MMBAN-ES
-XX:ErrorFile=/applog/eslog/MMBAN-ES/hs_err_pid%p.log
8:-XX:+PrintGCDetails
8:-XX:+PrintGCDateStamps
8:-XX:+PrintTenuringDistribution
8:-XX:+PrintGCApplicationStoppedTime
8:-Xloggc:/applog/eslog/MMBAN-ES/gc.log
8:-XX:+UseGCLogFileRotation
8:-XX:NumberOfGCLogFiles=32
8:-XX:GCLogFileSize=64m
9-:-Xlog:gc*,gc+age=trace,safepoint:file=/applog/eslog/MMBAN-ES/gc.log:utctime,pid,tags:filecount=32,filesize=64m
-Dlog4j2.formatMsgNoLookups=true
EOF
~~~

#### 4.3.3.日志文件

~~~shell
root@MES01 /app/elasticsearch-7.17.5/config # vim log4j2.properties 

修改
appender.rolling.strategy.action.condition.nested_condition.type = IfLastModified

注释
#appender.rolling.strategy.action.condition.nested_condition.exceeds = 2GB

增加
appender.rolling.strategy.action.condition.nested_condition.age = 90D
~~~

## 5.systemd 启动 ES

~~~shell
##1.同步elasticsearch相关文件
root@MES01 /app # RsyncData.sh  elasticsearch-7.17.5/
root@MES01 /app # 


root@MES01 /app # cat > /usr/lib/systemd/system/elasticsearch.service << EOF
[Unit]
Description=elasticsearch
After=network.target

[Service]
Type=simple
LimitMEMLOCK=infinity
Environment=JAVA_HOME=/app/elasticsearch-7.17.5/jdk
ExecStart=/app/elasticsearch-7.17.5/bin/elasticsearch
User=appuser
LimitNOFILE=131070
LimitNPROC=8192

[Install]
WantedBy=multi-user.target
EOF


##2.启动ES进程加入集群 （使用appuser用户操作）


##3.先启动主节点 cluster.initial_master_nodes: ["MES01:9305"]



##4.启动其他Master节点，并验证集群状态是否正常



##5.启动其他数据节点

#####启动命令
root@MES01 /root # chown  -R elasticsearch:elasticsearch /appdata /applog /app

root@MES01 /root # systemctl  daemon-reload 

root@MES01 /root # systemctl  enable  --now elasticsearch.service

root@MES01 /root # systemctl  restart elasticsearch.service

root@MES01 /root # systemctl  status   elasticsearch.service 

root@MES01 /root # tail  -f /applog/eslog/MMBAN-ES/MMBAN-ES.log 
~~~

### 5.1.1.集群检查

~~~shell
##1.基本检查
root@MES01 /root # ps -ef |grep elasticsearch

root@MES01 /root # ss -lutn |  grep :9205
tcp   LISTEN 0      2048   [::ffff:192.168.1.51]:9205            *:*   

root@MES01 /root # ss -lutn |  grep :9305
tcp   LISTEN 0      2048   [::ffff:192.168.1.51]:9305            *:* 


##2.es集群状态是否为green
root@MES01 /root # curl -X GET -H 'Content-Type: application/json' "http://192.168.1.51:9200/_cluster/health?pretty"
{
  "cluster_name" : "MMBAN-ES",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 9,
  "number_of_data_nodes" : 6,
  "active_primary_shards" : 3,
  "active_shards" : 6,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}


##3.检查新节点是否已成功加入集群
root@MES01 /root # curl -X GET "http://192.168.1.51:9200/_cat/nodes?h=name,ip,version,node.role,heap.max&pretty"
DES01 192.168.1.61 7.17.5 cdfhilrstw 512mb
MES02 192.168.1.52 7.17.5 ilmr       512mb
DES64 192.168.1.64 7.17.5 cdfhilrstw 512mb
DES02 192.168.1.62 7.17.5 cdfhilrstw 512mb
DES05 192.168.1.65 7.17.5 cdfhilrstw 512mb
MES01 192.168.1.51 7.17.5 ilmr       512mb
DES03 192.168.1.63 7.17.5 cdfhilrstw 512mb
MES03 192.168.1.53 7.17.5 ilmr       512mb
DES06 192.168.1.66 7.17.5 cdfhilrstw 512mb
~~~



